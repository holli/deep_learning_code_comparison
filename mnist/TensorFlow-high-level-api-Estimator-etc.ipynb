{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/tf_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/tf_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/tf_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/tf_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_input_data = input_data.read_data_sets('./data/tf_data') #, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_len 55000, test_len 10000\n"
     ]
    }
   ],
   "source": [
    "mnist_train = mnist_input_data.train\n",
    "mnist_test = mnist_input_data.test\n",
    "print(\"train_len {}, test_len {}\".format(mnist_train.num_examples, mnist_test.num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample class: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fedb3fa9940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sample class: {}\".format(mnist_train.labels[0]))\n",
    "sample_img = mnist_train.images[0]\n",
    "sample_img = sample_img.reshape(28,28)\n",
    "# print(\"Sample size: {}\".format(mnist_train.images[0].size()))\n",
    "plt.imshow(sample_img).set_cmap('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph with high level apis: tf.estimator and tf.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    x = features['x']\n",
    "    \n",
    "    x = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "    x = tf.layers.conv2d(inputs=x, filters=32, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
    "    x = tf.layers.max_pooling2d(inputs=x, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    x = tf.layers.conv2d(inputs=x, filters=64, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
    "    x = tf.layers.max_pooling2d(inputs=x, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    x = tf.reshape(x, [-1, 7 * 7 * 64]) # flatten 7,7,64 tensor\n",
    "    \n",
    "    x = tf.layers.dense(inputs=x, units=1024, activation=tf.nn.relu)\n",
    "    # dropout layer which is only used in training\n",
    "    x = tf.layers.dropout(inputs=x, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    y_results = tf.layers.dense(inputs=x, units=10)\n",
    "\n",
    "    predictions = {\n",
    "      \"classes\": tf.argmax(input=y_results, axis=1, name='class_predictor'),\n",
    "      \"probabilities\": tf.nn.softmax(y_results, name=\"classes_softmax_prob\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    else:\n",
    "        onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "        #onehot_labels = labels\n",
    "        loss_op = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=y_results)\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "            train_op = optimizer.minimize(loss=loss_op, global_step=tf.train.get_global_step(), name='train_op')\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss_op, train_op=train_op)\n",
    "        else: # EVAL mode\n",
    "            eval_metric_ops = {\n",
    "              \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss_op, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'classes': array([3]),\n",
       "  'probabilities': array([[ 0.10817411,  0.1061146 ,  0.09063991,  0.1085377 ,  0.10166859,\n",
       "           0.10352095,  0.09055026,  0.09612758,  0.09685247,  0.09781384]], dtype=float32)}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model_fn(PREDICT) manually by running one prediction.\n",
    "tf.reset_default_graph()\n",
    "x_ph = tf.placeholder(tf.float32, [None, 784], name='x_ph')\n",
    "#y_targets_ph = tf.placeholder(tf.float32, [None, 10], name='y_targets_ph')\n",
    "y_targets_ph = tf.placeholder(tf.float32, [None], name='y_targets_ph')\n",
    "estimator = model_fn({'x': x_ph}, y_targets_ph, tf.estimator.ModeKeys.PREDICT)\n",
    "#estimator = model_fn(x_ph, y_targets_ph, tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "sess.run([estimator[0]], feed_dict={x_ph: np.expand_dims(mnist_test.images[0], 0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model_fn(TRAIN) manually, should return [None]\n",
    "tf.reset_default_graph()\n",
    "x_ph = tf.placeholder(tf.float32, [None, 784], name='x_ph')\n",
    "y_targets_ph = tf.placeholder(tf.float32, [None], name='y_targets_ph')\n",
    "estimator = model_fn({'x': x_ph}, y_targets_ph, tf.estimator.ModeKeys.TRAIN)\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "op = tf.get_default_graph().get_operation_by_name('train_op')\n",
    "sess.run([op], feed_dict={x_ph: np.expand_dims(mnist_test.images[0], 0),\n",
    "                                    y_targets_ph: np.expand_dims(mnist_test.labels[0], 0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using estimator to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp6rbr5pnq\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {}\n",
      "tensorboard --logdir /tmp/tmp6rbr5pnq\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "\n",
    "# If you want to monitor more closesly you can start tensorboard with following command\n",
    "# and then start the browser as tensorboard guides you to\n",
    "print(\"tensorboard --logdir {}\".format(estimator.model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": mnist_test.images}, y=np.asarray(mnist_test.labels, dtype=np.int32),\n",
    "    num_epochs=1, shuffle=False)\n",
    "def test_model_accuracy():\n",
    "    eval_results = estimator.evaluate(input_fn=eval_input_fn)\n",
    "    print(\"Test_model_accuracy: \" + str(eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': mnist_train.images}, y=np.asarray(mnist_train.labels, dtype=np.int32),\n",
    "    batch_size=32, num_epochs=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp6rbr5pnq/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2898, step = 1\n",
      "INFO:tensorflow:global_step/sec: 238.387\n",
      "INFO:tensorflow:loss = 0.237525, step = 101 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.08\n",
      "INFO:tensorflow:loss = 0.284098, step = 201 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.159\n",
      "INFO:tensorflow:loss = 0.0703174, step = 301 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.361\n",
      "INFO:tensorflow:loss = 0.0426512, step = 401 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.433\n",
      "INFO:tensorflow:loss = 0.0392076, step = 501 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.823\n",
      "INFO:tensorflow:loss = 0.0296013, step = 601 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.449\n",
      "INFO:tensorflow:loss = 0.0166791, step = 701 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.865\n",
      "INFO:tensorflow:loss = 0.168788, step = 801 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.668\n",
      "INFO:tensorflow:loss = 0.0744926, step = 901 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.924\n",
      "INFO:tensorflow:loss = 0.160484, step = 1001 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.903\n",
      "INFO:tensorflow:loss = 0.0301684, step = 1101 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.496\n",
      "INFO:tensorflow:loss = 0.103366, step = 1201 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.579\n",
      "INFO:tensorflow:loss = 0.0161069, step = 1301 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.457\n",
      "INFO:tensorflow:loss = 0.0798899, step = 1401 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.193\n",
      "INFO:tensorflow:loss = 0.146272, step = 1501 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.083\n",
      "INFO:tensorflow:loss = 0.0112714, step = 1601 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.393\n",
      "INFO:tensorflow:loss = 0.11585, step = 1701 (0.348 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1719 into /tmp/tmp6rbr5pnq/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0799821.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-05-18:29:12\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp6rbr5pnq/model.ckpt-1719\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-05-18:29:12\n",
      "INFO:tensorflow:Saving dict for global step 1719: accuracy = 0.987, global_step = 1719, loss = 0.036051\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Test_model_accuracy: {'accuracy': 0.98699999, 'loss': 0.036051016, 'global_step': 1719}\n",
      "Epoch: 1\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp6rbr5pnq/model.ckpt-1719\n",
      "INFO:tensorflow:Saving checkpoints for 1720 into /tmp/tmp6rbr5pnq/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.056555, step = 1720\n",
      "INFO:tensorflow:global_step/sec: 308.866\n",
      "INFO:tensorflow:loss = 0.0374668, step = 1820 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.618\n",
      "INFO:tensorflow:loss = 0.0595774, step = 1920 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.874\n",
      "INFO:tensorflow:loss = 0.0529955, step = 2020 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.723\n",
      "INFO:tensorflow:loss = 0.00417351, step = 2120 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.77\n",
      "INFO:tensorflow:loss = 0.067279, step = 2220 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.383\n",
      "INFO:tensorflow:loss = 0.0262653, step = 2320 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.418\n",
      "INFO:tensorflow:loss = 0.00120508, step = 2420 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.615\n",
      "INFO:tensorflow:loss = 0.00504687, step = 2520 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.806\n",
      "INFO:tensorflow:loss = 0.0188873, step = 2620 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.25\n",
      "INFO:tensorflow:loss = 0.0257659, step = 2720 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.616\n",
      "INFO:tensorflow:loss = 0.0281801, step = 2820 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.058\n",
      "INFO:tensorflow:loss = 0.120051, step = 2920 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.536\n",
      "INFO:tensorflow:loss = 0.0451242, step = 3020 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.18\n",
      "INFO:tensorflow:loss = 0.0334519, step = 3120 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.818\n",
      "INFO:tensorflow:loss = 0.0886852, step = 3220 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.249\n",
      "INFO:tensorflow:loss = 0.000768861, step = 3320 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.394\n",
      "INFO:tensorflow:loss = 0.0187889, step = 3420 (0.307 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3438 into /tmp/tmp6rbr5pnq/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00334215.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-05-18:29:18\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp6rbr5pnq/model.ckpt-3438\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-05-18:29:19\n",
      "INFO:tensorflow:Saving dict for global step 3438: accuracy = 0.991, global_step = 3438, loss = 0.0287168\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Test_model_accuracy: {'accuracy': 0.991, 'loss': 0.028716827, 'global_step': 3438}\n",
      "Epoch: 2\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp6rbr5pnq/model.ckpt-3438\n",
      "INFO:tensorflow:Saving checkpoints for 3439 into /tmp/tmp6rbr5pnq/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0123201, step = 3439\n",
      "INFO:tensorflow:global_step/sec: 314.481\n",
      "INFO:tensorflow:loss = 0.0177262, step = 3539 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.593\n",
      "INFO:tensorflow:loss = 0.00256269, step = 3639 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.215\n",
      "INFO:tensorflow:loss = 0.231646, step = 3739 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.536\n",
      "INFO:tensorflow:loss = 0.000176263, step = 3839 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.175\n",
      "INFO:tensorflow:loss = 0.0854551, step = 3939 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.901\n",
      "INFO:tensorflow:loss = 0.0284229, step = 4039 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.757\n",
      "INFO:tensorflow:loss = 0.0105894, step = 4139 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.871\n",
      "INFO:tensorflow:loss = 0.00332401, step = 4239 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.326\n",
      "INFO:tensorflow:loss = 0.0104965, step = 4339 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.438\n",
      "INFO:tensorflow:loss = 0.00803449, step = 4439 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.599\n",
      "INFO:tensorflow:loss = 0.000598406, step = 4539 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.69\n",
      "INFO:tensorflow:loss = 0.00879708, step = 4639 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.692\n",
      "INFO:tensorflow:loss = 0.0253875, step = 4739 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.943\n",
      "INFO:tensorflow:loss = 0.000596273, step = 4839 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.023\n",
      "INFO:tensorflow:loss = 0.0165153, step = 4939 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.206\n",
      "INFO:tensorflow:loss = 0.0157734, step = 5039 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.86\n",
      "INFO:tensorflow:loss = 0.0051631, step = 5139 (0.310 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5157 into /tmp/tmp6rbr5pnq/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0035584.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-05-18:29:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp6rbr5pnq/model.ckpt-5157\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-05-18:29:25\n",
      "INFO:tensorflow:Saving dict for global step 5157: accuracy = 0.9893, global_step = 5157, loss = 0.0352284\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Test_model_accuracy: {'accuracy': 0.98930001, 'loss': 0.03522845, 'global_step': 5157}\n",
      "Epoch: 3\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp6rbr5pnq/model.ckpt-5157\n",
      "INFO:tensorflow:Saving checkpoints for 5158 into /tmp/tmp6rbr5pnq/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0295564, step = 5158\n",
      "INFO:tensorflow:global_step/sec: 298.643\n",
      "INFO:tensorflow:loss = 0.0031046, step = 5258 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.265\n",
      "INFO:tensorflow:loss = 0.0241479, step = 5358 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.347\n",
      "INFO:tensorflow:loss = 0.00619762, step = 5458 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.894\n",
      "INFO:tensorflow:loss = 0.000733362, step = 5558 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.794\n",
      "INFO:tensorflow:loss = 0.0162757, step = 5658 (0.319 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 302.357\n",
      "INFO:tensorflow:loss = 0.00146911, step = 5758 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.979\n",
      "INFO:tensorflow:loss = 0.00373631, step = 5858 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.703\n",
      "INFO:tensorflow:loss = 0.0126342, step = 5958 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.131\n",
      "INFO:tensorflow:loss = 5.42686e-05, step = 6058 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.165\n",
      "INFO:tensorflow:loss = 0.000604316, step = 6158 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.94\n",
      "INFO:tensorflow:loss = 0.00826757, step = 6258 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.305\n",
      "INFO:tensorflow:loss = 0.00111393, step = 6358 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.644\n",
      "INFO:tensorflow:loss = 0.0184049, step = 6458 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.839\n",
      "INFO:tensorflow:loss = 0.0299011, step = 6558 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.945\n",
      "INFO:tensorflow:loss = 0.023183, step = 6658 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.345\n",
      "INFO:tensorflow:loss = 0.00312481, step = 6758 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.028\n",
      "INFO:tensorflow:loss = 0.0374473, step = 6858 (0.321 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6876 into /tmp/tmp6rbr5pnq/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00299699.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-05-18:29:31\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp6rbr5pnq/model.ckpt-6876\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-05-18:29:32\n",
      "INFO:tensorflow:Saving dict for global step 6876: accuracy = 0.991, global_step = 6876, loss = 0.0282951\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Test_model_accuracy: {'accuracy': 0.991, 'loss': 0.028295085, 'global_step': 6876}\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    estimator.train(input_fn=train_input_fn, steps=len(mnist_train.images)/32)\n",
    "    test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-10-05-18:29:32\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp6rbr5pnq/model.ckpt-6876\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-05-18:29:32\n",
      "INFO:tensorflow:Saving dict for global step 6876: accuracy = 0.991, global_step = 6876, loss = 0.0282951\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Test_model_accuracy: {'accuracy': 0.991, 'loss': 0.028295085, 'global_step': 6876}\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is fancy way to save estimators, load and serve them, but I didn't manage to do that here.\n",
    "\n",
    "https://www.tensorflow.org/programmers_guide/saved_model#using_savedmodel_with_estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_def]",
   "language": "python",
   "name": "conda-env-py3_def-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
